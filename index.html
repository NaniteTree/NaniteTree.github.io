<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Nanite Tree Imposter to Mesh Simplification">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Nanite Tree Imposter to Mesh Simplification</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/ICON.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          Language
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://nanitetree.github.io">
            CN
          </a>
          <a class="navbar-item" href="https://hypernerf.github.io">
            EN
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Nanite Tree Pipeline</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/jiayaozhang">Jiayao Zhang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/Hikohikoyan">Hikohikoyan</a><sup>2</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Cloud Imperium Games,</span>
            <span class="author-block"><sup>2</sup>Tencent Games</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://github.com/jiayaozhang/NaniteTree_Imposter2Mesh_Simplification"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

              <span class="link-block">
                <a href="https://www.bilibili.com/video/BV1Pk4y1Q7sm/?spm_id_from=333.337.top_right_bar_window_history.content.click&vd_source=1805bbf959fd5bce323236f76f8b8d64"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Video</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/Showcase.mp4"
                type="video/mp4">
      </video>
      <div class="content">
        <p>Left Tree is generated after our Nanite Tree Pipeline, rendered with Opaque leaf material. Right Tree is created using traditional manual workflows, rendered with Masked material and leaf mask textures.</p>
        <p>Performance: with both tree enabled Nanite & WorldPositionOffset Animation, right tree consumes 2 to 3 times more performance than to the left Tree. 
          Furthermore, when Nanite is disabled, the performance of right tree increases another 3 ms.</p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This is an automated Nanite Tree Tool designed to convert traditional non-Nanite vegetation models into Nanite models suitable for Unreal Engine 5.

            The core functions of this tool include vertex layout reconstruction, polygon merging, and LOD generation, aiming to simplify the process of vegetation asset creation and improve artistic creation efficiency.

            Through our tool, artists can quickly convert original billboard models to leaf modeling vegetation models suitable for Nanite rendering, 
            achieving higher-quality rendering effects and better performance. 
          </p>
  
        </div>
      </div>
    </div>
 
    <div class="is-centered has-text-centered">
      <div class="is-four-fifths">
        <div class="is-3 has-text-centered">
          <img src="https://hikohiko.notion.site/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F0d608712-81b7-41af-8caa-374d0e8f6ab6%2F714956db-3786-48f2-a62e-c90608e43e69%2FUntitled.png?table=block&id=bff8adc8-38f5-4a4c-8eb2-947c8014ca45&spaceId=0d608712-81b7-41af-8caa-374d0e8f6ab6&width=2000&userId=&cache=v2"
               class="interpolation-image"
               alt="Interpolation end reference image."/>
          <p class="is-bold">Details of NaniteTreePipeline has been revealed at the 2023 UE Fest speech</p>
        </div>
      </div>
    </div> 
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
<!-- Paper video. -->
<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Overview of Asset Export to Unreal</h2>
    <p>
      Automatically recognize tree trunks , leaves and LODs , UCX based on input rules.
    </p>
    <div class="publication-video">
      <video id="process" autoplay muted loop playsinline height="10%">
        <source src="./static/videos/GetInput.mp4"
                type="video/mp4">
      </video>
        </div>
  </div>
</div> 
</section>

<!-- Pipeline Overview -->
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Pipeline Overview</h2>
        <div class="content has-text-justified">
          <p>
            In addition to providing automated asset conversion functions,
            this tool also allows artists to fine-tune parameters as needed to optimize the final rendering effects. 
            By validating the impact of each modification on the final effect in the engine, artists can achieve satisfactory rendering results faster.
         </p>
         <p>
           As an open-source project, 
           this tool provides a reliable solution for the vegetation creation process in Unreal Engine 5 and contributes a practical technical tool to the game development community.
            Through open-source, we hope to inspire more developers to participate and collectively drive technological advancement and creative efficiency in the gaming industry.
         </p>
        </div>
      </div>
    </div>

  </section>
<!--/ Pipeline Overview -->

<!-- Pipeline Charts -->
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4">What kind of projects are suitable?</h2>
        <div class="content has-text-justified">
          <p class="is-bold">
            - High-quality rendering effects are pursued<br>
            - Aspiring to elevate quality beyond traditional handcrafted models, and extend the project to achieve a level of ultra-high quality (such as movie-grade)
            <br>
            - Interested in exploring the performance and effects of Nanite
         </p>
          <img src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F0d608712-81b7-41af-8caa-374d0e8f6ab6%2Fc8027de5-f8ad-4ab1-b82a-77c3cff236fe%2FUntitled.png?table=block&id=7ae8413b-c83b-462f-95d7-98c90a7cb22a&spaceId=0d608712-81b7-41af-8caa-374d0e8f6ab6&width=2000&userId=80ccc004-e910-4733-adda-0a0d5ae9d3d2&cache=v2" alt="Pipeline suitable chart" height="200%">
          <img src="https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F0d608712-81b7-41af-8caa-374d0e8f6ab6%2F98b1847f-10c8-445a-b2fd-f742bf9dfd59%2FUntitled.png?table=block&id=e5b1d9e9-b4b1-424a-b2af-58d0bbcde246&spaceId=0d608712-81b7-41af-8caa-374d0e8f6ab6&width=2000&userId=80ccc004-e910-4733-adda-0a0d5ae9d3d2&cache=v2" alt="Pipeline suitable chart" height="200%">
        </div>
      </div>
    </div>

  </section>
<!--/ Pipeline Charts -->

<!-- Houdini Part Start -->

<section class="section">
  <div class="container is-centered">

      <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <div class="content has-text-justified">
          <h2 class="title is-3">Houdini</h2>
          <h3>Using with HDK & Python</h3>
          <br>
          <p>
            Enter the model file and set the corresponding rule parameters (such as the leaf material name of your model, this will be used to identify and distinguish the leaf part from the trunk part)
          </p>
        </div>
        </div>
      </div>

      <div class="column">
        <br><br>
        <div class="content has-text-justified">
          <img src="./static/images/3.png"
                class="interpolation-image"
                alt="HDA Preview 5"/>
        </div>
      </div>
    </div>
</section>
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <!-- <div class="item item-chair-tp">
          <img src="./static/images/1.png" alt="Chair Image" height="200%">
        </div> -->
        <div class="item item-chair-tp">
          <img src="./static/images/2.png" alt="HDA Preview " height="200%">
        </div>
        <!-- <div class="item item-shiba">
          <img src="./static/images/3.png" alt="Chair Image" height="800%">
        </div>
        <div class="item item-fullbody">
          <img src="./static/images/4.png" alt="Chair Image" height="800%">
        </div> -->
        <div class="item item-blueshirt">
          <img src="./static/images/5.png" alt="HDA Preview 1" height="200%">
        </div>
        <div class="item item-mask">
          <img src="./static/images/6.png" alt="HDA Preview 2" height="200%">
        </div>
        <div class="item item-coffee">
          <img src="./static/images/7.png" alt="HDA Preview 3" height="200%">
        </div>
        <div class="item item-toby">
          <img src="./static/images/8.png" alt="HDA Preview 4" height="200%">
        </div>
      </div>
    </div>
  </div>
</section>




<!--/ Houdini Part  End -->
<!-- UnrealPlugin Part Start -->
<section class="section">
  <div class="container is-centered">
    <!-- Houdini Part Start -->
      <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <div class="content has-text-justified">
          <h2 class="title is-3">Unreal Plugin</h2>
          <h3>Using with HDA</h3>
          <br>
          <p>
            Enter the model file and set the corresponding rule parameters (such as the leaf material name of your model, this will be used to identify and distinguish the leaf part from the trunk part)
          </p>
        </div>
      </div>
    </div>
      <div class="column">
        <br><br>
        <div class="content has-text-justified">
          <img src="./static/images/config1.png"
          class="column is-vcentered"
          alt="Interpolation end reference image."/>
      </div>
      <div class="content has-text-justified">
        <img src="./static/images/config2.png"
              class="column is-vcentered"
              alt="Interpolation end reference image."/>
        </div>
      </div>
    </div>
</section>
<!--/ UnrealPlugin Part  End -->


 <!-- Effect Contrast. -->
<!-- Leaves Mesh Generation -->
<section class="section">
  <div class="container is-centered">
    <!-- Houdini Part Start -->
      <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <div class="content has-text-justified">
          <h2 class="title is-3">Effect Contrast</h2>
          <h3>Leaves Mesh Generation</h3>
          <br>
          <p>
            Enter the model file and set the corresponding rule parameters (such as the leaf material name of your model, this will be used to identify and distinguish the leaf part from the trunk part)
          </p>
        </div>
      </div>
    </div>

      <div class="column">
        <br><br>
        <div class="content has-text-justified">
          <img src="./static/images/leaf1.png"
               width="100%"
               alt="Interpolation end reference image."/>
      </div>
      <div class="content has-text-justified">
        <img src="./static/images/leaf2.png"
        width="100%"
        alt="Interpolation end reference image."/>
        </div>
      </div>
    </div>
</section>
 <!-- Leaves Mesh Generation -->

<!-- Nanite Virtual Geometry start-->
<section class="section">
  <div class="container is-centered">
    <!-- Houdini Part Start -->
      <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <div class="content has-text-justified">
          <h2 class="title is-3">Nanite virtual Geometry Technology</h2>
          <h3>GPU-Driven Pipeline</h3>
          <br>
          <p>
            “GPU-Driven” is also a well-discussed topic. In the traditional Vertex-Raster-Pixel Shading pipeline execution process, the GPU front end, after processing instructions from the Host Interface, has the Primitive Distributor distribute mesh information in batches from the Index Buffer to various GPCs (in the case of Nvidia GPUs). Within the SM unit, the PolyMorph Engine takes on responsibilities such as Vertex Fetch, Tessellation, Viewport Transform, Attributes Setup, and Stream Out, connecting the rendering pipeline’s upstream and downstream segments. Under the guidance of the Warp Scheduler, thread bundles complete Vertex calculations, then pack the data to the Raster Engine for hardware rasterization. The processed data is then sent back to the SM unit for Pixel stage shading and ultimately output by the ROP. The entire process is seamless, and apart from the programmable parts in the GPU stages, there is limited control. The remaining logic computations and organizational aspects are predominantly handled by the CPU.
          </p>
          <p>
            On one hand, the increasing pressure on the CPU makes it desirable for the GPU to assist in computations beyond rendering. On the other hand, there is a desire for even more precise culling than at the Object or Instance level. Given the compactness of the aforementioned pipeline, it is necessary to find an executor for this work outside the traditional rendering pipeline, and currently, the only option seems to be the Compute Shader! With capable hands on deck, the next step is to address one crucial aspect: how the GPU independently tackles computation, decision-making, and most importantly, the DrawCall problem. Thanks to certain features of new versions of Graphics APIs, such as Indirect Draw, some tasks that were originally entirely CPU-implemented can be delegated to the GPU for computation and data read/write operations. This approach not only reduces the communication latency between GPU and CPU but also maximizes the GPU’s parallel computing capabilities to further refine culling granularity, thus reducing OverDraw in the rendering pipeline. This is the essence of the GPU-Driven approach.
          </p>
          <p>
            In this field, some projects provide valuable engineering references, such as Ubisoft’s presentation on “GPU-Driven Rendering Pipelines” at SIGGRAPH 2015 1, where they discussed various GPU-based culling techniques, including Cluster-based culling and the support of Virtual Texture throughout the GPU-driven pipeline. They introduced an intriguing concept called “Single Draw Call Rendering,” where an entire scene is rendered with a single Draw Call. Although somewhat idealized, it indeed significantly improves overall performance.

            Following this, at GDC 2016, EA’s Frostbite Engine presented their GPU-Driven solution in “Optimizing the Graphics Pipeline with Compute” 2. In the subsequent years, Ubisoft continued to share GPU-Driven rendering solutions in 2018 and 2019 at GDC. These included the terrain rendering approach in “Far Cry 5” 3 and “GPU Driven Rendering and Virtual Textureing in ‘Trials Rising’” 4.
            
            Unreal Engine 4 (UE4) also designed its GPU-Driven solution in earlier versions, and these technological foundations have now been employed as part of the Nanite framework. Essentially, the entire Nanite framework is built upon GPU-Driven principles.          
          </p>
        </div>
        </div>
      </div>

      <div class="column">
        <br><br>
        <div class="content has-text-justified">
          <img src="./static/images/pipeline.png"
               width="100%"
               alt="Interpolation end reference image."/>
      </div>
      <br><br> <br><br>
      <div class="content has-text-justified">
        <img src="./static/images/nanite.png"
             width="100%"
             alt="Interpolation end reference image."/>
    </div>
      </div>
    </div>
</section>
<!-- Nanite Virtual Geometry end-->


<!-- Nanite Virtual Geometry start-->
<section class="section">
  <div class="container is-centered">
    <!-- Houdini Part Start -->
      <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <div class="content has-text-justified">
          <h3>Hardware & Software rasterization</h3>
          <br>
          <p>
            Nanite employs a hybrid rasterization strategy, addressing the fundamental question of when hardware rasterization is appropriate versus when software rasterization is more suitable.
            Hardware rasterization typically involves two steps: Coarse Rasterization at an 8x8 pixel block level and Fine Rasterization at a 2x2 pixel block level. During Coarse Rasterization, obscured blocks are culled using a low-resolution Z-Buffer, leaving only the visible areas for shading. Then, Fine Rasterization operates at a 2x2 pixel block level (Pixel Quad) to perform the final rasterization output. This design choice, with blocks of 2x2 pixels, enables access to neighboring pixel information for executing DDX, DDY operations to facilitate hardware-level MIP calculations. The historical rationale behind this design stems from early days when most triangles were significantly larger than a single pixel. Compared to the extensive fetch of vertex attributes, texture sampling, and numerous shading calculations, hardware rasterization incurred relatively low overhead in the rendering pipeline, making it highly efficient for most scenarios.
            However, this “one-size-fits-most” approach occasionally leads to significant inefficiencies, especially when scenes contain a high density of triangles, with many triangles occupying less than a single pixel. In such cases, the coarse culling in Coarse Rasterization becomes largely ineffective, and Fine Rasterization faces substantial waste. For instance, a small triangle spanning three Pixel Quads may realistically cover only three pixels, but the 2x2 Quad mechanism would process all twelve pixels, resulting in considerable computational overhead.
            In scenarios like these, where triangles densely populate the viewport and many occupy less than a single pixel, software rasterization can be more efficient. Coupled with GPU-Driven techniques, Cluster or Meshlet-level culling further narrows down the triangle range for rasterization. Most importantly, the entire system seamlessly integrates into a unified pipeline.
          </p>
        </div>
        </div>
      </div>

      <div class="column">
        <br><br><br><br>
        <div class="content has-text-justified">
          <img src="./static/images/meshlets.png"
               width="50%"
               style="margin-left: 120px;" 
               alt="Interpolation end reference image."/>
      </div>
      </div>
    </div>
</section>
<!-- Nanite Virtual Geometry end-->


<!-- Meshlets Pipelines Generation -->
<section class="section">
  <div class="container is-centered">
    <!-- Houdini Part Start -->
      <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <div class="content has-text-justified">
          <h3>MeshShader</h3>
          <br>
          <p>
            Nvidia unveiled its proprietary Mesh Shader pipeline at SIGGRAPH 2019, taking GPU-Driven approaches directly to the hardware level in a single leap. The rationale behind this advancement lies in addressing the potential “inefficiency” risk associated with traditional GPU-Driven methods, primarily stemming from the historical baggage of the rasterization pipeline’s execution flow.

            Without considering technologies like Virtual Texturing (VT), GPU-Driven solutions primarily tackle culling issues. If a target triangle is successfully culled, it’s advantageous. However, if not, it involves a convoluted process of data storage, computation, register writing, and subsequent reading. This is because, without considering software rasterization, the triangle ultimately needs to return to the original rendering pipeline, undergoing another Vertex Fetch process. Before Vertex Fetch, there are fixed pipelines like Primitive Distributor that cannot be bypassed.
            
            Nvidia’s solution involves a radical departure by discarding the traditional Vertex Shader (VS), Tessellation, and Geometry stages. Instead, they establish a new paradigm where Meshlets, after collaborative thread group computations for culling, seamlessly interface with the hardware rasterizer. This streamlined approach ensures a more efficient and direct integration of GPU-Driven techniques into the hardware pipeline.          </p>
            <p>
              In this setup, the Task Shader essentially takes on the role of culling previously handled by Compute Shaders (CS), while the Mesh Shader itself assumes responsibility for geometric topology. However, it’s notable that Nanite is not based on Mesh Shader technology. The question arises: Why? One speculation is that Mesh Shaders might not directly address the challenge of handling vast numbers of small triangles. Additionally, the current high hardware costs for users adopting Mesh Shader technology could hinder its widespread adoption. Therefore, a more conservative approach utilizing Compute Shaders for GPU-Driven techniques and a hybrid rasterization scheme might be preferable. According to official statements, Nanite’s innovation lies in LOD (Level of Detail) construction and Culling, areas that have been the focal points of technical showcase by major game developers over the past decade.
            </p>
          </div>
      </div>
    </div>

      <div class="column">
        <!-- <br><br> -->
        <div class="content has-text-justified">
          <img src="./static/images/meshpipeline.png"
               width="100%"
               alt="Interpolation end reference image."/>
      </div>
      <div class="content has-text-justified">
        <img src="./static/images/meshpipeline2.png"
        width="100%"
        alt="Interpolation end reference image."/>
        </div>
      </div>
    </div>
</section>
 <!-- Meshlets Pipeline Generation -->


<!-- Nanite Virtual Geometry start-->
<section class="section">
  <div class="container is-centered">
    <!-- Houdini Part Start -->
      <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <div class="content has-text-justified">
            <h2 class="title is-3">Nanite Detailed Analysis</h2>
          <br>
          <p>
            The comprehensive implementation of Nanite involves a multitude of engineering accumulations, including GPU-Driven, software rasterization, geometric modeling, BMT processing, and data compression. What is particularly commendable is the integration of these diverse elements into an already intricate Deferred rendering architecture while ensuring that it runs efficiently and maintains transparency in the upper-level design processes. Transparency in this context means that changes in the underlying architecture do not impact the users' original methods of operation and development workflows. Achieving this requires not only extensive knowledge in graphics development but also a seasoned proficiency in engine engineering, substantial courage, and even a touch of audacious spirit.
            From a macro perspective, the overall Nanite rendering pipeline can be outlined as follows:
            Now, let's delve into an analysis of each key stage.
          </p>
        </div>
        </div>
      </div>

      <div class="column">
        <br><br><br><br>
        <div class="content has-text-justified">
          <img src="./static/images/cluster.png"
               width="100%"
               alt="Interpolation end reference image."/>
      </div>
      </div>
    </div>
</section>
<!-- Nanite Virtual Geometry end-->






<!-- Meshlets Pipelines Generation -->
<section class="section">
  <div class="container is-centered">
    <!-- Houdini Part Start -->
      <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <div class="content has-text-justified">

          <h3>Cluster Building Stage</h3>
          <br>
          <p>
            The entire mesh is divided into clusters, each consisting of 128 triangles, following the “Lowest Contribution Boundary” and “As Uniform Area as Possible” partitioning strategy between clusters. This ensures minimal errors in subsequent simplification processes. The logic for LOD construction is as follows: Initially, 32 to 64 clusters form a Cluster Group. A crucial step in this process is the Lock Edge operation performed on the Cluster Group, which is fundamental to ensuring a well-structured partition. Subsequently, triangles within the group undergo a merging process, gradually eliminating internal boundaries without affecting the group’s perimeter. This step employs a dedicated triangle simplifier using the QEM (Quadratic Error Metric) simplification algorithm. This yields a LOD1-level Cluster Group. The next step involves performing splits within the LOD1-level Cluster Group, effectively re-partitioning the triangles.
          </p>
          <p>
            From the simplification diagram above each cluster represented by 4 triangles for illustration], it can be observed that the boundaries and shapes of the triangles generated after simplification are no longer related to the original LOD level. The simplification process is not a crude “merge” or “collapse” of triangles; instead, the outer boundaries of the entire group are locked. The simplification process adheres to the strategy of “Lowest Contribution Boundary” and “As Uniform Area as Possible,” ensuring that each simplification maintains consistent area proportions and coverage between the “triangular strips.” This minimizes projection errors and enhances texture mapping precision.
          </p>
          <p>
            Each iteration follows the aforementioned principles, and after each generation of a new LOD through Grouping, Merging, Simplification, and Splitting, the errors for each Cluster and Group are recorded. These errors, along with the errors from the next iteration, are used to calculate the maximum error metric (Max Error Metric). This results in a LOD tree where errors are in descending order with an increase in face count. This enables subsequent comparisons of screen projection ratios and errors to dynamically select the appropriate LOD level. The iterator generates a tree structure with a root node containing only one Cluster, and a BVH (Bounding Volume Hierarchy) is built based on this structure to accelerate GPU-Driven Culling. The entire process is parallelized.
            After BVH construction, a paged data storage model is established on a Cluster Group basis, with each page being 128kb. A constraint is imposed that only Cluster Groups that are spatially adjacent and belong to the same LOD are placed in the same page. To ensure spatial adjacency and data layout continuity, “Morton 3D” is employed. Notably, the vertex information held by the Nanite Mesh is minimal, potentially lacking data such as Vertex Tangents. Tangent data is calculated in real-time based on existing point attributes, following two principles: first, eliminate data that can be calculated to save storage, I/O pressure, and index calculations; second, minimize the bit count for mandatory attributes.
            After the completion of the Nanite Mesh construction process, a crucial step is data compression. Given the large number of vertices and the need for a global Vertex Buffer for efficient real-time streaming operations, data compression is essential. The specific compression algorithm is yet to be determined, but it involves a trade-off between precision loss and performance. Epic Games undoubtedly aims to strike the optimal balance.
          </p>
          </div>
      </div>
    </div>

      <div class="column">
        <br><br><br><br>
        <div class="content has-text-justified">
          <img src="./static/images/cluster1.png"
          width="100%"
          alt="Interpolation end reference image."/>
          </div>
          <br><br>
          <div class="content has-text-justified">
            <img src="./static/images/qem.png"
            width="100%"
            alt="Interpolation end reference image."/>
            </div>
      </div>
    </div>
</section>
 <!-- Meshlets Pipeline Generation -->






<!-- Nanite Virtual Geometry start-->
<section class="section">
  <div class="container is-centered">
    <!-- Houdini Part Start -->
      <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <div class="content has-text-justified">
            <h2 class="title is-3">Culling Stage</h2>
          <br>
          <p>
            Culling in Nanite is entirely GPU-driven. The process includes View Frustum Culling and Hierarchical Z-Buffer (HZB) culling. Backface Culling and Small Triangle Culling are not performed at this stage. There are three levels of culling. First is at the Instance level, which is the granularity achievable by traditional rendering pipelines. Next, after Instance culling, the Mesh undergoes BVH (Bounding Volume Hierarchy) Node Culling, which is hierarchical and dynamic.
            Ensuring load balancing across Compute Shader (CS) thread groups is crucial, ensuring that each thread is fully utilized without idling. Due to potentially significant differences in BVH depth for each Mesh, it’s inappropriate to allocate thread groups based on Cluster leaf nodes. In UE5, a global First-In-First-Out (FIFO) queue is maintained to retrieve BVH nodes. If a node passes culling, all its child nodes are moved to the end of the queue. This process continues until the global queue is empty. This approach ensures that the processing time is roughly equal among threads. Nodes that pass are further subjected to Cluster-level culling, and after three levels of culling, the retained triangle faces exhibit significantly reduced waste compared to traditional pipelines.
          </p>
          <p>
            In reality, the entire culling process consists of two passes: the Main Pass and the Post Pass. From the diagram, these two passes share similar logic, with the difference lying in the fact that the occlusion culling in the Main Pass is based on data from the previous frame, whereas the Post Pass utilizes the Hierarchical Z-Buffer (HZB) constructed at the end of the Main Pass for the current frame. The primary purpose of these two passes is to enhance the accuracy of culling.
            Additionally, during the Cluster culling stage, triangles are marked to determine whether they will undergo software rasterization or hardware rasterization, depending on their size.
          </p>
        </div>
        </div>
      </div>

      <div class="column">
        <br><br><br><br>
        <div class="content has-text-justified">
          <img src="./static/images/culling.png"
               width="100%"
               alt="Interpolation end reference image."/>
      </div>
      </div>
    </div>
</section>
<!-- Nanite Virtual Geometry end-->




<!-- Nanite Virtual Geometry start-->
<section class="section">
  <div class="container is-centered">
    <!-- Houdini Part Start -->
      <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <div class="content has-text-justified">
            <h2 class="title is-3">Culling Stage</h2>
          <br>
          <p>
            The Visibility Buffer can achieve storage with fewer index details, typically involving InstanceID, PrimitiveID, MaterialID, and Depth. As it stores index information, its volume is inherently smaller than that of the G-Buffer. However, it requires maintaining a global set of Vertex Attributes and a Material Map. In the Shading stage, the process involves indexing relevant triangle information from the global Vertex Buffer based on InstanceID and PrimitiveID. Pixel-wise information is then interpolated based on barycentric coordinates. Material information is obtained from MaterialID, and together they enter the lighting calculation process to achieve the final shading. This process, to some extent, allows for the separation of geometric and shading calculations, a feat not achievable in traditional Deferred rendering, where G-Buffer serves as the bridge between geometry and shading.          </p>
          <p>
            In the Nanite workflow, the format of the Visibility Buffer is R32G32_UNIT, where R’s 0-6 bits store Triangle ID, 7-31 bits store Cluster ID, and G contains 32-bit Depth information. Considering the Deferred architecture of the UE4 era, on the one hand, Nanite currently cannot support all types of rendering, and some meshes still need to be rendered using the traditional rendering pipeline. On the other hand, as mentioned by Karis, a crucial premise of this architectural adjustment is transparency to users. This means that changes in the underlying structure should not impact user-level habits or require relearning the engine, which is crucial. To ensure compatibility between the new and old rendering pipelines, there is an Emit Targets stage to connect Nanite with the traditional deferred rendering approach.          </p>
          <p>
            The Emit Targets stage is further divided into EmitDepthTargets and EmitGBuffer phases. Initially, besides the Visibility Buffer, shading requires additional data to blend with hard rasterization data. Nanite employs several full-screen passes to write information outside the Visibility Buffer (such as Velocity, Stencil, Nanite Mask, MaterialID) into a unified buffer, preparing for the subsequent GBuffer reconstruction. Specifically, Emit Scene Depth writes the Depth from the Visibility Buffer into the Scene Depth buffer, Emit Velocity writes into the Velocity Buffer, Emit Scene Stencil writes into the Stencil buffer, and Emit Material Depth writes into the Material ID buffer.

            Regarding the MaterialID Buffer, several strategies are employed, depending on the scene’s material complexity. When there are numerous materials, the screen is divided into 64x64 blocks, and the minimum and maximum values of materials in each block are calculated. This calculation is executed by a full-screen Compute Shader, resulting in an image called Material Range. With this image, in the EmitGbuffer phase, a full-screen draw is triggered for each material, where culling is completed in the Vertex Shader (VS) stage. In the Pixel Shader (PS) stage, shading is applied only to corresponding pixels through Depth Compare, thus outputting information such as Albedo into the GBuffer.
          </p>
          </div>
        </div>
      </div>

      <div class="column">
        <br><br><br><br><br><br>
        <div class="content has-text-justified">
          <img src="./static/images/visibility.png"
               width="100%"
               alt="Interpolation end reference image."/>
      </div>
      <br><br><br><br>
      <div class="content has-text-justified">
        <img src="./static/images/Emit.png"
             width="100%"
             alt="Interpolation end reference image."/>
    </div>
      </div>
    </div>
</section>
<!-- Nanite Virtual Geometry end-->




 <section class="section">
  <div class="container is-max-desktop">
    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced for Nanite Tree Simplification.
          </p>
          <p>
            <a href="https://faculty.cc.gatech.edu/~turk/my_papers/memless_vis98.pdf">Lindstrom-Turk Cost and Placement Strategy</a> introduces edge collapse operation for triangle Simplification.
          </p>
          <p>
            <a href="https://faculty.cc.gatech.edu/~turk/my_papers/memless_vis98.pdf">Garland-Heckbert Cost and Placement Strategy</a> based on iterative edge contraction and quadric error metrics.
          </p>
          <p>
            <a href="https://faculty.cc.gatech.edu/~turk/my_papers/memless_vis98.pdf">Cost Strategy Policies</a> is selected through three strategies: GetPlacement, GetCost and Filter.
          </p>
          <p>
            SIGGRAPH 2015 ubisoft, <a href="http://advances.realtimerendering.com/s2015/aaltonenhaar_siggraph2015_combined_final_footer_220dpi.pdf">GPU-Driven Rendering Pipelines</a> 
          </p>
          <p>
            GDC 2018 Ubisoft, <a href="https://www.gdcvault.com/play/1025480/Terrain-Rendering-in-Far-Cry">Terrian Rendering in "Far Cry 5"</a> 
          </p>
          <p>
            GDC 2019 Ubisoft, <a href="https://ubm-twvideo01.s3.amazonaws.com/o1/vault/gdc2019/presentations/Drazhevskyi_Oleksandr_GPU_Driven_Rendering.pdf">GPU Driven Rendering and Virtual Textureing in "Trials Rising"   </a> 
          </p>
          <p>
            Based on Turing architecture GPU <a href="https://developer.nvidia.com/zh-cn/blog/introduction-turing-mesh-shaders">Mesh Shader </a> 
          </p>
          <p>
            SIGGRAPH 2021 Epic Games Brian Karis  <a href="https://advances.realtimerendering.com/s2021/Karis_Nanite_SIGGRAPH_Advances_2021_final.pdf">Nanite A Deep Dive </a> 
          </p>
          <p>
            Mi Wang  <a href="https://www.gameres.com/891789.html">Unreal Engine 5 development roadmap and technical analysis </a> 
          </p>
          <p>
            Jiff   <a href="https://zhuanlan.zhihu.com/p/376267968">UE5 Nanite Brief analysis of implementation </a> 
          </p>
          <p>
            Cheng Luo  <a href="https://zhuanlan.zhihu.com/p/382687738#ref_6">Introduction to UE Rendering Technology: Nanite  </a> 
          </p>
          <p>
            Yue Cong  <a href="https://zhuanlan.zhihu.com/p/377652639">UE5 Nanite source code analysis for rendering: Rasterization</a> 
          </p>
          <p>
            Wang Xiang  <a href="https://www.cnblogs.com/timlly/p/14927797.html">UE5 Special Part 1: Nanite </a> 
          </p>
          <p>
            Helo <a href="https://zhuanlan.zhihu.com/p/477998497">Nanite vegetation creation guide in UE5 </a> 
          </p>

        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{nanitetree,
  author    = {jiayaozhang,Hikohuang},
  title     = {Nanite Tree Pipeline},
  year      = {2023},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/jiayaozhang/NaniteTree" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Showcase.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!-- <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Showcase.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Showcase.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Showcase.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/bShowcase.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Showcase.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Showcase.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Showcase.mp4"
                    type="video/mp4">
          </video>
        </div> -->
      <!-- </div>
    </div>
  </div>
</section> -->
</body>
</html>
